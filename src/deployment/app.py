"""
ä¸­æ–‡æ–°é—»åˆ†ç±» Gradio Demo
åŠ è½½è®­ç»ƒå¥½çš„BERTæ¨¡å‹ï¼Œå®ç°Webç•Œé¢é¢„æµ‹
"""

import gradio as gr
import torch
from transformers import BertTokenizer, BertForSequenceClassification
import sys
sys.path.append('../..')

# é…ç½®
MODEL_PATH = '../../output/bert_best.pth'
MODEL_NAME = 'bert-base-chinese'

# ç±»åˆ«æ˜ å°„
label_map = {
    0: 'ä½“è‚²', 1: 'å¨±ä¹', 2: 'å®¶å±…', 3: 'å½©ç¥¨', 4: 'æˆ¿äº§', 5: 'æ•™è‚²',
    6: 'æ—¶å°š', 7: 'æ—¶æ”¿', 8: 'æ˜Ÿåº§', 9: 'æ¸¸æˆ', 10: 'ç¤¾ä¼š', 11: 'ç§‘æŠ€',
    12: 'è‚¡ç¥¨', 13: 'è´¢ç»'
}

# åŠ è½½æ¨¡å‹
print("åŠ è½½BERTæ¨¡å‹...")
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)

model = BertForSequenceClassification.from_pretrained(
    MODEL_NAME,
    num_labels=14
)
model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
model.to(device)
model.eval()

print(" æ¨¡å‹åŠ è½½å®Œæˆ")


def predict_news(text):
    """
    é¢„æµ‹æ–°é—»ç±»åˆ«

    Args:
        text: æ–°é—»æ–‡æœ¬

    Returns:
        é¢„æµ‹ç»“æœå­—å…¸ {ç±»åˆ«: æ¦‚ç‡}
    """
    if not text.strip():
        return {"é”™è¯¯": "è¯·è¾“å…¥æ–°é—»æ–‡æœ¬"}

    # Tokenize
    encoding = tokenizer(
        text,
        max_length=128,
        padding='max_length',
        truncation=True,
        return_tensors='pt'
    )

    # ç§»åˆ°GPU/CPU
    input_ids = encoding['input_ids'].to(device)
    attention_mask = encoding['attention_mask'].to(device)

    # é¢„æµ‹
    with torch.no_grad():
        outputs = model(input_ids=input_ids, attention_mask=attention_mask)
        logits = outputs.logits
        probs = torch.softmax(logits, dim=1)[0]

    # è½¬ä¸ºå­—å…¸ {ç±»åˆ«: æ¦‚ç‡}
    results = {}
    for i, prob in enumerate(probs.cpu().numpy()):
        category = label_map[i]
        results[category] = float(prob)

    return results


# ===== Gradioç•Œé¢ =====

# ç¤ºä¾‹æ–‡æœ¬
examples = [
    ["ä¸­å›½ç”·ç¯®åœ¨ä¸–ç•Œæ¯ä¸Šå–å¾—ä¼˜å¼‚æˆç»©ï¼Œçƒè¿·æ¬¢å‘¼é›€è·ƒ"],
    ["è‚¡å¸‚ä»Šæ—¥å¤§æ¶¨ï¼Œä¸Šè¯æŒ‡æ•°çªç ´3000ç‚¹"],
    ["äººå·¥æ™ºèƒ½æŠ€æœ¯çªç ´ï¼Œæ·±åº¦å­¦ä¹ åº”ç”¨å¹¿æ³›"],
    ["æœ€æ–°ç”µå½±ä¸Šæ˜ ï¼Œç¥¨æˆ¿å¤§å–"]
]

# åˆ›å»ºç•Œé¢
demo = gr.Interface(
    fn=predict_news,
    inputs=gr.Textbox(
        label="è¾“å…¥æ–°é—»æ–‡æœ¬",
        placeholder="è¯·è¾“å…¥ä¸€æ®µæ–°é—»...",
        lines=5
    ),
    outputs=gr.Label(
        label="åˆ†ç±»ç»“æœ",
        num_top_classes=5  # æ˜¾ç¤ºTop 5ç±»åˆ«
    ),
    title="ğŸ—ï¸ ä¸­æ–‡æ–°é—»åˆ†ç±»ç³»ç»Ÿ",
    description="""
    åŸºäºBERTçš„ä¸­æ–‡æ–°é—»åˆ†ç±»ï¼ˆ14ç±»ï¼‰
    - æ¨¡å‹ï¼šbert-base-chineseå¾®è°ƒ
    - å‡†ç¡®ç‡ï¼š96.99%
    - æ•°æ®é›†ï¼šTHUCNews
    """,
    examples=examples,
    theme="default"
)

# å¯åŠ¨
if __name__ == "__main__":
    demo.launch(
        share=False,  # Trueä¼šç”Ÿæˆå…¬å¼€é“¾æ¥
        server_port=7860
    )