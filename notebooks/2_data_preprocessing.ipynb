{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-29T11:28:01.192634Z",
     "start_time": "2025-10-29T11:28:00.484226Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\dl\\lib\\site-packages\\jieba\\_compat.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "70c532e6666be163",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T11:28:17.284793Z",
     "start_time": "2025-10-29T11:28:15.152827Z"
    }
   },
   "source": [
    "train_df=pd.read_csv('../data/processed/train.csv')\n",
    "test_df=pd.read_csv('../data/processed/test.csv')\n",
    "val_df=pd.read_csv('../data/processed/val.csv')\n",
    "print(f'训练集{train_df.shape}')\n",
    "print(f'测试集{test_df.shape}')\n",
    "print(f'验证集{val_df.shape}')\n",
    "print(f\"\\n类别: {train_df['label'].unique()}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集(45462, 4)\n",
      "测试集(9743, 4)\n",
      "验证集(9742, 4)\n",
      "\n",
      "类别: [13  9  6  7  3  0 10  2  5 12  4  1 11  8]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "1388b9f15c7afacc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T11:28:26.295830Z",
     "start_time": "2025-10-29T11:28:26.284768Z"
    }
   },
   "source": [
    "# 中文停用词表\n",
    "stopwords = set([\n",
    "    '的', '了', '在', '是', '我', '有', '和', '就', '不', '人', '都',\n",
    "    '一', '一个', '上', '也', '很', '到', '说', '要', '去', '你', '会',\n",
    "    '着', '没有', '看', '好', '自己', '这', '中', '以', '来', '个',\n",
    "    '地', '为', '他', '得', '她', '对', '么', '里', '后', '能', '再',\n",
    "    '而', '被', '从', '把', '让', '与', '等', '别', '之', '这个',\n",
    "])\n",
    "\n",
    "print(f\"停用词数量: {len(stopwords)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "停用词数量: 53\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "5ac5f6ce3aeb6f49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T11:31:23.498924Z",
     "start_time": "2025-10-29T11:31:22.271800Z"
    }
   },
   "source": [
    "def tokenize(text):\n",
    "    words=jieba.cut(text)\n",
    "    words=[w for w in words if w not in stopwords]\n",
    "    return words\n",
    "# 测试分词\n",
    "sample_text = train_df.iloc[0]['text']\n",
    "print(\"原文:\")\n",
    "print(sample_text[:100])\n",
    "print(\"\\n分词后:\")\n",
    "print(\" / \".join(tokenize(sample_text)[:20]))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\ysn\\AppData\\Local\\Temp\\jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原文:\n",
      "成长型基金猜想2009：幸福岁月能否延续\n",
      "　　实习记者 杨颖桦 本报记者 张桔 \n",
      "　　究竟是全市场基金还是成长型基金会在2009年走牛？种种迹象显示答案是后者。 \n",
      "　　银河证券基金研究中心的统计显示，\n",
      "\n",
      "分词后:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 1.215 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成长型 / 基金 / 猜想 / 2009 / ： / 幸福 / 岁月 / 能否 / 延续 / \n",
      " / 　 / 　 / 实习 / 记者 /   / 杨颖桦 /   / 本报记者 /   / 张桔\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "1e143489a8077c91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T11:35:21.922886Z",
     "start_time": "2025-10-29T11:31:54.985177Z"
    }
   },
   "source": [
    "# 对所有数据分词\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 重要！先启用pandas的进度条\n",
    "tqdm.pandas()\n",
    "train_df['words']=train_df['text'].progress_apply(tokenize)\n",
    "test_df['words']=test_df['text'].progress_apply(tokenize)\n",
    "val_df['words']=val_df['text'].progress_apply(tokenize)\n",
    "\n",
    "print(\"\\n 分词完成！\")\n",
    "\n",
    "# 查看分词后的结果\n",
    "print(\"\\n示例（前3条）:\")\n",
    "for i in range(3):\n",
    "    print(f\"\\n第{i+1}条:\")\n",
    "    print(f\"标签: {train_df.iloc[i]['label']}\")\n",
    "    print(f\"分词: {' '.join(train_df.iloc[i]['words'][:15])}...\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45462/45462 [02:26<00:00, 310.68it/s]\n",
      "100%|██████████| 9743/9743 [00:28<00:00, 341.82it/s]\n",
      "100%|██████████| 9742/9742 [00:32<00:00, 303.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 分词完成！\n",
      "\n",
      "示例（前3条）:\n",
      "\n",
      "第1条:\n",
      "标签: 13\n",
      "分词: 成长型 基金 猜想 2009 ： 幸福 岁月 能否 延续 \n",
      " 　 　 实习 记者  ...\n",
      "\n",
      "第2条:\n",
      "标签: 9\n",
      "分词: 《 侠盗 车手 》 将 推出 续作   明年 亮相 E3 \n",
      " 　 　 由...\n",
      "\n",
      "第3条:\n",
      "标签: 6\n",
      "分词: 组图 ： 6 款 性感 丝袜 最配 夏季 超短 \n",
      " 　 　 导读 ： 穿...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "ac6a8f86c1878870",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T11:35:48.292262Z",
     "start_time": "2025-10-29T11:35:44.574424Z"
    }
   },
   "source": [
    "all_words=[]\n",
    "for word in train_df['words']:\n",
    "    all_words.extend(word)\n",
    "    \n",
    "word_freq=Counter(all_words)\n",
    "print(f\"总词: {len(all_words)}\")\n",
    "print(f\"不重复词数:{word_freq}\")\n",
    "\n",
    "min_freq=5\n",
    "word_freq={word:freq for word, freq in word_freq.items() if freq>=min_freq}\n",
    "print(f\"保留词数: {len(word_freq)}\")\n",
    "\n",
    "sorted_words=sorted(word_freq.items(), key=lambda x:x[1], reverse=True)\n",
    "# 构建词到ID的映射\n",
    "vocab = {'<PAD>': 0, '<UNK>': 1}  # 特殊token\n",
    "for word, freq in sorted_words:\n",
    "    vocab[word] = len(vocab)\n",
    "\n",
    "print(f\"\\n词表大小: {len(vocab):,}\")\n",
    "\n",
    "print(f\"\\nTop 20 高频词:\")\n",
    "for i, (word, freq) in enumerate(sorted_words[:20], 1):\n",
    "    print(f\"{i:2d}. {word}: {freq:,}\")\n",
    "\n",
    "# 保存词表\n",
    "with open('../data/processed/vocab.pkl', 'wb') as f:\n",
    "    pickle.dump(vocab, f)\n",
    "\n",
    "print(\"\\n 词表已保存到 data/processed/vocab.pkl\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总词: 23111713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 词表已保存到 data/processed/vocab.pkl\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "1c7145cbb1c4d50e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T11:37:33.645371Z",
     "start_time": "2025-10-29T11:37:29.090157Z"
    }
   },
   "source": [
    "# Cell 7: 文本转ID序列\n",
    "print(\"将文本转换为ID序列...\")\n",
    "\n",
    "def words_to_ids(words, vocab, max_len=512):\n",
    "    \"\"\"将词列表转换为ID列表\"\"\"\n",
    "    ids = [vocab.get(word, vocab['<UNK>']) for word in words]\n",
    "\n",
    "    if len(ids) > max_len:\n",
    "        ids = ids[:max_len]\n",
    "    else:\n",
    "        ids = ids + [vocab['<PAD>']] * (max_len - len(ids))\n",
    "\n",
    "    return ids\n",
    "\n",
    "# 转换\n",
    "train_df['ids'] = train_df['words'].apply(lambda x: words_to_ids(x, vocab))\n",
    "val_df['ids'] = val_df['words'].apply(lambda x: words_to_ids(x, vocab))\n",
    "test_df['ids'] = test_df['words'].apply(lambda x: words_to_ids(x, vocab))\n",
    "\n",
    "print(\"ID转换完成！\")\n",
    "\n",
    "# 示例\n",
    "idx = 0\n",
    "print(f\"\\n示例:\")\n",
    "print(f\"原文: {train_df.iloc[idx]['text'][:50]}...\")\n",
    "print(f\"分词: {' '.join(train_df.iloc[idx]['words'][:10])}...\")\n",
    "print(f\"ID序列前20个: {train_df.iloc[idx]['ids'][:20]}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "将文本转换为ID序列...\n",
      "ID转换完成！\n",
      "\n",
      "示例:\n",
      "原文: 成长型基金猜想2009：幸福岁月能否延续\n",
      "　　实习记者 杨颖桦 本报记者 张桔 \n",
      "　　究竟是全市场基...\n",
      "分词: 成长型 基金 猜想 2009 ： 幸福 岁月 能否 延续 \n",
      "...\n",
      "ID序列前20个: [29558, 34, 9530, 151, 10, 1720, 5850, 1432, 1596, 5, 3, 3, 2944, 45, 6, 1, 6, 1160, 6, 89093]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "ac3ed2fd1e7e778a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T11:39:28.660121Z",
     "start_time": "2025-10-29T11:39:28.646884Z"
    }
   },
   "source": [
    "# Cell 8: 保存标签映射\n",
    "import pickle\n",
    "\n",
    "# THUCNews 14个类别\n",
    "label_map_save = {\n",
    "    0: '体育', 1: '娱乐', 2: '家居', 3: '彩票', 4: '房产', 5: '教育',\n",
    "    6: '时尚', 7: '时政', 8: '星座', 9: '游戏', 10: '社会', 11: '科技',\n",
    "    12: '股票', 13: '财经'\n",
    "}\n",
    "\n",
    "with open('../data/processed/label_map.pkl', 'wb') as f:\n",
    "    pickle.dump(label_map_save, f)\n",
    "\n",
    "print(\"标签映射已保存\")\n",
    "print(\"\\n标签映射:\")\n",
    "for k, v in label_map_save.items():\n",
    "    print(f\"{k:2d} → {v}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标签映射已保存\n",
      "\n",
      "标签映射:\n",
      " 0 → 体育\n",
      " 1 → 娱乐\n",
      " 2 → 家居\n",
      " 3 → 彩票\n",
      " 4 → 房产\n",
      " 5 → 教育\n",
      " 6 → 时尚\n",
      " 7 → 时政\n",
      " 8 → 星座\n",
      " 9 → 游戏\n",
      "10 → 社会\n",
      "11 → 科技\n",
      "12 → 股票\n",
      "13 → 财经\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "7f8bbe1a37989281",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T11:40:50.103083Z",
     "start_time": "2025-10-29T11:40:19.482115Z"
    }
   },
   "source": [
    "# Cell 9: 保存最终数据并总结\n",
    "import pickle\n",
    "\n",
    "print(\"保存最终处理结果...\")\n",
    "\n",
    "# 保存完整数据（包含text, label, label_name, words, ids等）\n",
    "train_df.to_pickle('../data/processed/train_processed.pkl')\n",
    "val_df.to_pickle('../data/processed/val_processed.pkl')\n",
    "test_df.to_pickle('../data/processed/test_processed.pkl')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🎉 数据预处理全部完成！\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n数据统计:\")\n",
    "print(f\"  训练集: {len(train_df):,} 条\")\n",
    "print(f\"  验证集: {len(val_df):,} 条\")\n",
    "print(f\"  测试集: {len(test_df):,} 条 （有label，可以评估）\")\n",
    "print(f\"  词表大小: {len(vocab):,}\")\n",
    "print(f\"  类别数: 14\")\n",
    "print(f\"  序列长度: 512\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存最终处理结果...\n",
      "\n",
      "============================================================\n",
      "🎉 数据预处理全部完成！\n",
      "============================================================\n",
      "\n",
      "数据统计:\n",
      "  训练集: 45,462 条\n",
      "  验证集: 9,742 条\n",
      "  测试集: 9,743 条 （有label，可以评估）\n",
      "  词表大小: 117,355\n",
      "  类别数: 14\n",
      "  序列长度: 512\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "719a524a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3ffd0c21302fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
