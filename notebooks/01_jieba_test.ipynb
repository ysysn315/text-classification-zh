{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# jieba分词实验\n",
    "\n",
    "Day 1: 熟悉jieba中文分词工具\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T11:39:24.379259Z",
     "start_time": "2025-10-27T11:39:23.511100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\dl\\lib\\site-packages\\jieba\\_compat.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 导入成功\n"
     ]
    }
   ],
   "source": [
    "# 导入库\n",
    "import jieba\n",
    "from collections import Counter\n",
    "\n",
    "print(\"✅ 导入成功\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T11:43:13.869437Z",
     "start_time": "2025-10-27T11:43:13.843445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "精确模式: 我 / 爱 / 自然语言处理 / 和 / 深度学习\n",
      "<generator object Tokenizer.cut at 0x0000023BA13A40B0>\n"
     ]
    }
   ],
   "source": [
    "# 基础分词测试\n",
    "text = \"我爱自然语言处理和深度学习\"\n",
    "\n",
    "# 精确模式\n",
    "words = jieba.cut(text, cut_all=False)\n",
    "print(\"精确模式:\", \" / \".join(words))\n",
    "print(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T11:43:00.461505Z",
     "start_time": "2025-10-27T11:43:00.437055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "添加词典后: 深度学习 / 在 / 自然语言处理 / 中 / 应用 / 广泛\n"
     ]
    }
   ],
   "source": [
    "# 添加自定义词典\n",
    "jieba.add_word('深度学习')\n",
    "jieba.add_word('自然语言处理')\n",
    "jieba.add_word('机器学习')\n",
    "\n",
    "text2 = \"深度学习在自然语言处理中应用广泛\"\n",
    "words = jieba.cut(text2)\n",
    "print(\"添加词典后:\", \" / \".join(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T11:44:15.456074Z",
     "start_time": "2025-10-27T11:44:15.438537Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去除停用词: 今天 / 天气 / 我们 / 一起 / 电影吧\n"
     ]
    }
   ],
   "source": [
    "# 停用词过滤\n",
    "stopwords = set(['的', '了', '在', '是', '我', '有', '和', '就', \n",
    "                 '不', '人', '都', '一', '一个', '上', '也', '很',\n",
    "                 '到', '说', '要', '去', '你', '会', '着', '没有'])\n",
    "\n",
    "text3 = \"今天的天气很好，我们一起去看电影吧\"\n",
    "words = [w for w in jieba.cut(text3) if w not in stopwords and len(w) > 1]\n",
    "print(\"去除停用词:\", \" / \".join(words))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T11:45:05.705082Z",
     "start_time": "2025-10-27T11:45:05.691450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ jieba分词实验完成！\n",
      "下一步: 安装依赖、下载THUCNews数据集\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n✅ jieba分词实验完成！\")\n",
    "print(\"下一步: 安装依赖、下载THUCNews数据集\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T12:01:49.543338Z",
     "start_time": "2025-10-27T12:00:51.653817Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d4c16eb756549adbdab1bbe8f259d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\dl\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ysn\\.cache\\huggingface\\hub\\datasets--clue. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e3ebf02fc5645f18b1cd7dccd4713f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/655k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea74e30db97446859ada14883279a5e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/3.40M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49b586118553471395b45c137e47095e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/643k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7535e4de7b2944fd8b8571dab6f04143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac43fe8874f44738a3b493022dc745c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/53360 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "760753430fa1448f8b720370b342c1d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 53360\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# 从HuggingFace下载TNEWS（中文新闻分类）\n",
    "from datasets import load_dataset\n",
    "\n",
    "# TNEWS: 今日头条中文新闻分类\n",
    "dataset = load_dataset(\"clue\", \"tnews\")\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T12:09:24.755211Z",
     "start_time": "2025-10-27T12:09:24.723436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集字段:\n",
      "['sentence', 'label', 'idx']\n",
      "\n",
      "第一条数据:\n",
      "{'sentence': '上课时学生手机响个不停，老师一怒之下把手机摔了，家长拿发票让老师赔，大家怎么看待这种事？', 'label': 7, 'idx': 0}\n",
      "\n",
      "数据结构:\n",
      "{'sentence': Value('string'), 'label': ClassLabel(names=['100', '101', '102', '103', '104', '106', '107', '108', '109', '110', '112', '113', '114', '115', '116']), 'idx': Value('int32')}\n"
     ]
    }
   ],
   "source": [
    "# 查看数据集有哪些字段\n",
    "print(\"训练集字段:\")\n",
    "print(dataset['train'].column_names)\n",
    "\n",
    "print(\"\\n第一条数据:\")\n",
    "print(dataset['train'][0])\n",
    "\n",
    "print(\"\\n数据结构:\")\n",
    "print(dataset['train'].features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T12:19:26.357490Z",
     "start_time": "2025-10-27T12:19:25.969686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 文件读取成功！\n",
      "\n",
      "训练集: 53360 条\n",
      "验证集: 10000 条\n",
      "测试集: 10000 条\n",
      "\n",
      "训练集前3条:\n",
      "                                             text  label\n",
      "0    上课时学生手机响个不停，老师一怒之下把手机摔了，家长拿发票让老师赔，大家怎么看待这种事？    NaN\n",
      "1  商赢环球股份有限公司关于延期回复上海证券交易所对公司2017年年度报告的事后审核问询函的公告    NaN\n",
      "2                通过中介公司买了二手房，首付都付了，现在卖家不想卖了。怎么处理？    NaN\n",
      "\n",
      "类别统计:\n",
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# 读取保存的CSV文件\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('../data/processed/train.csv')\n",
    "val = pd.read_csv('../data/processed/val.csv')\n",
    "test = pd.read_csv('../data/processed/test.csv')\n",
    "\n",
    "print(\"✅ 文件读取成功！\")\n",
    "print(f\"\\n训练集: {len(train)} 条\")\n",
    "print(f\"验证集: {len(val)} 条\")\n",
    "print(f\"测试集: {len(test)} 条\")\n",
    "\n",
    "print(f\"\\n训练集前3条:\")\n",
    "print(train.head(3))\n",
    "\n",
    "print(f\"\\n类别统计:\")\n",
    "print(train['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T11:57:04.860674Z",
     "start_time": "2025-10-28T11:57:00.281546Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "重新划分数据集...\n",
      "合并后总数据: 63360\n",
      "\n",
      "重新划分后:\n",
      "训练集: 44352 (70.0%)\n",
      "验证集: 9504 (15.0%)\n",
      "测试集: 9504 (15.0%)\n",
      "\n",
      "类别分布（训练集）:\n",
      "label_name\n",
      "科技    4931\n",
      "财经    4309\n",
      "娱乐    4120\n",
      "国际    4029\n",
      "汽车    3436\n",
      "文化    3372\n",
      "体育    3331\n",
      "军事    3044\n",
      "教育    2858\n",
      "旅游    2843\n",
      "游戏    2834\n",
      "农业    2366\n",
      "房产    1740\n",
      "故事     928\n",
      "股票     211\n",
      "Name: count, dtype: int64\n",
      "\n",
      "前3条数据:\n",
      "                                 text  label label_name\n",
      "32360                         玉兰花开红艳艳     13         农业\n",
      "9467   建造一艘航母有多难？从一飞行甲板就能看出来，你知道有多厚吗？      9         军事\n",
      "43946               河南，湖南，海南谁在世界知名度高？     11         国际\n",
      "\n",
      "✅ 数据重新划分并保存完成！\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "print(\"重新划分数据集...\")\n",
    "\n",
    "# 只使用训练集和验证集（它们有真实label）\n",
    "# 合并训练集和验证集\n",
    "train_original = []\n",
    "for item in dataset['train']:\n",
    "    train_original.append({\n",
    "        'text': item['sentence'],\n",
    "        'label': item['label']\n",
    "    })\n",
    "\n",
    "val_original = []\n",
    "for item in dataset['validation']:\n",
    "    val_original.append({\n",
    "        'text': item['sentence'],\n",
    "        'label': item['label']\n",
    "    })\n",
    "\n",
    "# 合并\n",
    "all_data = train_original + val_original\n",
    "df_all = pd.DataFrame(all_data)\n",
    "\n",
    "print(f\"合并后总数据: {len(df_all)}\")\n",
    "\n",
    "# 重新划分：训练70% + 验证15% + 测试15%\n",
    "train_df, temp_df = train_test_split(\n",
    "    df_all,\n",
    "    test_size=0.3,  # 30%用于验证+测试\n",
    "    random_state=42,\n",
    "    stratify=df_all['label']  # 保持类别比例\n",
    ")\n",
    "\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=0.5,  # 30%的一半 = 15%\n",
    "    random_state=42,\n",
    "    stratify=temp_df['label']\n",
    ")\n",
    "\n",
    "print(f\"\\n重新划分后:\")\n",
    "print(f\"训练集: {len(train_df)} ({len(train_df)/len(df_all)*100:.1f}%)\")\n",
    "print(f\"验证集: {len(val_df)} ({len(val_df)/len(df_all)*100:.1f}%)\")\n",
    "print(f\"测试集: {len(test_df)} ({len(test_df)/len(df_all)*100:.1f}%)\")\n",
    "\n",
    "# 添加中文label\n",
    "label_map = {\n",
    "    0: '故事', 1: '文化', 2: '娱乐', 3: '体育', 4: '财经',\n",
    "    5: '房产', 6: '汽车', 7: '教育', 8: '科技', 9: '军事',\n",
    "    10: '旅游', 11: '国际', 12: '股票', 13: '农业', 14: '游戏'\n",
    "}\n",
    "\n",
    "train_df['label_name'] = train_df['label'].map(label_map)\n",
    "val_df['label_name'] = val_df['label'].map(label_map)\n",
    "test_df['label_name'] = test_df['label'].map(label_map)\n",
    "\n",
    "print(f\"\\n类别分布（训练集）:\")\n",
    "print(train_df['label_name'].value_counts())\n",
    "\n",
    "print(f\"\\n前3条数据:\")\n",
    "print(train_df[['text', 'label', 'label_name']].head(3))\n",
    "\n",
    "# 保存\n",
    "train_df.to_csv('../data/processed/train.csv', index=False, encoding='utf-8')\n",
    "val_df.to_csv('../data/processed/val.csv', index=False, encoding='utf-8')\n",
    "test_df.to_csv('../data/processed/test.csv', index=False, encoding='utf-8')\n",
    "\n",
    "print(\"\\n✅ 数据重新划分并保存完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
